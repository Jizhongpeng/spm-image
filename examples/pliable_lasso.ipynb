{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pliable Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats, linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# add parent directory to load spmimage\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(4)\n",
    "np.concatenate([np.array([1]), a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _soft_threshold(X: np.ndarray, thresh: float) -> np.ndarray:\n",
    "    return np.where(np.abs(X) <= thresh, 0, X - thresh * np.sign(X))\n",
    "\n",
    "def solve_quad_eq(a, b, c):\n",
    "    D = np.sqrt(b**2 - 4*a*c)\n",
    "    x_1 = (-b + D) / (2 * a)\n",
    "    x_2 = (-b - D) / (2 * a)\n",
    "    return x_1, x_2\n",
    "\n",
    "def _y_hat(beta, theta, X, W):\n",
    "    n_features = X.shape[1]\n",
    "    return np.sum([beta[j] * X[:, j] + W[j].dot(theta[:, j]) for j in range(n_features)])\n",
    "\n",
    "def _J(beta, theta, X, W, y, lam, alpha):\n",
    "    n_samples, n_features = X.shape[:2]\n",
    "    val = 1 / (2 * n_samples) * np.linalg.norm(y - _y_hat(beta, theta, X, W))\n",
    "    for j in range(n_features):\n",
    "        beta_theta_j = np.concatenate([np.array([beta[j]]), theta[:, j]])\n",
    "        val = val + (1 - alpha) * lam * (np.linalg.norm(beta_theta_j)\n",
    "                                         + np.linalg.norm(theta[:. j]))\n",
    "        val = val + alpha * lam * np.linalg.norm(theta[:, j], ord=1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bccd(X, Z, y, lam, alpha, t_init=0.1):\n",
    "    n_samples, n_features = X.shape[:2]\n",
    "    K = Z.shape[1]\n",
    "    W = [X[:, j].reshape(n_samples, 1) * Z for j in range(n_features)]\n",
    "    beta = np.zeros(n_features)\n",
    "    theta = np.zeros((K, n_features))\n",
    "    ones = np.ones(n_samples)\n",
    "    eps = 1e-6\n",
    "    \n",
    "    # get beta0 and theta0 by least square regression\n",
    "    Ztil = np.hstack((ones.reshape(-1, 1), Z))\n",
    "    beta0_theta0 = linalg.solve(Ztil.T.dot(Ztil), Ztil.T.dot(y))\n",
    "    beta0, theta0 = beta0_theta0[0], beta0_theta0[1:]\n",
    "    \n",
    "    y = y - beta0 * ones - Z.dot(theta0)\n",
    "    r = y\n",
    "    r_old = r\n",
    "    while True:\n",
    "        for j in range(n_features):\n",
    "            \n",
    "            # r_(-j)\n",
    "            rbj = r + beta[j] * X[:, j] + W[j].dot(theta[:, j])\n",
    "            \n",
    "            # checking if (beta_j, theta_j) = (0, 0)\n",
    "            if (abs(np.inner(X[:, j], rbj) / n_samples) <= (1 - alpha) * lam\n",
    "                and np.linalg.norm(_soft_threshold(W[j].T.dot(rbj) / n_samples, alpha * lam))\n",
    "                                   <= 2.0 * (1 - alpha) * lam):\n",
    "                beta[j] = 0\n",
    "                theta[:, j] = 0\n",
    "                continue\n",
    "            \n",
    "            # checking if theta_j = 0 and beta_j != 0\n",
    "            beta_j = n_samples / (X[:, j]**2).sum() \\\n",
    "                * _soft_threshold(np.inner(X[:, j], rbj) / n_samples, (1 - alpha) * lam)\n",
    "            if (np.linalg.norm(_soft_threshold(W[j].T.dot(rbj - beta_j * X[:, j])\n",
    "                                               / n_samples, alpha * lam))\n",
    "                <= (1 - alpha) * lam):\n",
    "                r = r - (beta_j - beta[j]) * X[:, j]\n",
    "                beta[j] = beta_j\n",
    "                theta[:, j] = 0\n",
    "                continue\n",
    "            \n",
    "            # (beta_j, theta_j) != (0, 0)\n",
    "            # generalized gradient descent\n",
    "            t = t_init\n",
    "            grbeta = -1 / n_samples * np.inner(X[:, j], r)\n",
    "            grtheta = -1 / n_samples * W[j].T.dot(r)\n",
    "            cri = 10e9\n",
    "            count = 0\n",
    "            # converge if change of residual is small\n",
    "            while(cri > eps):\n",
    "                count = count + 1\n",
    "                c = t * (1 - alpha) * lam\n",
    "                g1 = abs(beta[j] - t * grbeta)\n",
    "                g2 = np.linalg.norm(_soft_threshold(theta[:, j] - t * grtheta,\n",
    "                                                    t * alpha * lam))\n",
    "                r1, r2 = solve_quad_eq(1, 2 * c, 2 * c * g2 - g1**2 - g2**2)\n",
    "                a_list = [g1 * r1 / (c + r1), g1 * r2 / (c + r2),\n",
    "                          g1 * r1 / (c + r2), g1 * r2 / (c + r1)]\n",
    "                b_list = [r1 * (c - g2) / (c + r1), r2 * (c - g2) / (c + r2),\n",
    "                          r1 * (c - g2) / (c + r2), r2 * (c - g2) / (c + r1)]\n",
    "                min_val = 10e9\n",
    "                a_hat = 0\n",
    "                b_hat = 0\n",
    "                for a, b in product(a_list, b_list):\n",
    "                    gamma = np.sqrt(a**2 + b**2)\n",
    "                    val = (abs((1 + c / gamma) * a - g1)\n",
    "                           + abs((1 + c * (1 / b + 1 / gamma)) * b - g2))\n",
    "                    if val < min_val:\n",
    "                        min_val = val\n",
    "                        a_hat = a\n",
    "                        b_hat = b\n",
    "                if min_val > eps:\n",
    "                    print(min_val)\n",
    "                    print('Error: No solution was found in the equation.', file=sys.stderr)\n",
    "                    sys.exit(1)\n",
    "                if a_hat < 0 or b_hat < 0:\n",
    "                    print('Error: Negative solution was found in the equation.', file=sys.stderr)\n",
    "                    sys.exit(1)\n",
    "                gamma = np.sqrt(a_hat**2 + b_hat**2)\n",
    "                beta_j = (beta[j] - t * grbeta) / (1 + c / gamma)\n",
    "                theta_j = (_soft_threshold(theta[:, j] - t * grtheta, t * alpha * lam)\n",
    "                           / (1 + c * (1 / b_hat + 1 / gamma)))\n",
    "                r_new = r - (beta_j - beta[j]) * X[:, j] - W[j].dot(theta_j - theta[:, j])\n",
    "                \n",
    "                # condition for backtracking\n",
    "                if (((r_new**2).sum() / n_samples - (r**2).sum() / n_samples\n",
    "                     - 2.0 * ((beta_j - beta[j]) * grbeta\n",
    "                              + np.inner(theta_j - theta[:, j], grtheta))\n",
    "                     - ((beta_j - beta[j])**2 + ((theta_j - theta[:, j])**2).sum()) / t) < 0.0):\n",
    "                    beta[j] = beta_j\n",
    "                    theta[:, j] = theta_j\n",
    "                    cri = np.linalg.norm(r_new - r)\n",
    "                    r = r_new\n",
    "                    t = t_init\n",
    "                    grbeta = -1 / n_samples * np.inner(X[:, j], r)\n",
    "                    grtheta = -1 / n_samples * W[j].T.dot(r)\n",
    "                else:\n",
    "                    t = t * 0.9\n",
    "        # converge if change of residual is small\n",
    "        if np.linalg.norm(r - r_old) < eps:\n",
    "            break\n",
    "        r_old = r\n",
    "    print(beta0, theta0)\n",
    "    print(beta, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.05423613939284 [ 0.96633725 -1.79277856  0.46329511]\n",
      "[2.81157221 0.         0.        ] [[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [3.28630417 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "n = 20\n",
    "p = 3\n",
    "nz = 3\n",
    "x = np.random.normal(0, 1, (n, p))\n",
    "mx = np.mean(x, axis=0)\n",
    "sx = np.std(x, axis=0)\n",
    "x =stats.zscore(x)\n",
    "z = np.random.normal(0, 1, (n, nz))\n",
    "mz = np.mean(z, axis=0)\n",
    "sz = np.std(z, axis=0)\n",
    "z = stats.zscore(z)\n",
    "y = 4 * x[:, 0] + 5 * x[:, 0] * z[:, 2] + 3 * np.random.normal(n)\n",
    "_bccd(x, z, y, 1.0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
